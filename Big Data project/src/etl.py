# -*- coding: utf-8 -*-
"""etl.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jta4dTcHap1iHcEpmH_xVwjg_CZJB7s9
"""

import argparse
from pathlib import Path

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr, to_timestamp


def create_spark(app_name="retail_etl"):
    spark = SparkSession.builder.appName(app_name).getOrCreate()
    return spark


def etl(input_path: str, out_path: str):
    spark = create_spark()
    df = (
        spark.read.option("header", True).option("inferSchema", True).csv(input_path)
        .withColumn("InvoiceDate", to_timestamp(col("InvoiceDate")))
    )

    # Basic cleaning: remove cancellations, non-positive quantities/prices
    df = df.filter((col("Quantity") > 0) & (col("UnitPrice") > 0))

    # Add TotalSale column
    df = df.withColumn("TotalSale", expr("Quantity * UnitPrice"))

    # Write Parquet partitioned by country and year-month
    out_dir = Path(out_path)
    out_dir.parent.mkdir(parents=True, exist_ok=True)

    df.write.mode("overwrite").parquet(str(out_path))
    # .partitionBy("Country", "YearMonth") # Example partitioning, uncomment if needed

    print(f"Wrote Parquet to {out_path}")
    spark.stop()


if __name__ == "__main__":
    # For execution in Colab, we'll directly call etl with paths
    # If running as a command-line script, uncomment the argparse block below

    # parser = argparse.ArgumentParser()
    # parser.add_argument("--input", required=True)
    # parser.add_argument("--out", default="data/fact_retail.parquet")
    # args = parser.parse_args()
    # etl(args.input, args.out)

    # Example paths for Colab execution:
    example_input_path = "data/retail.csv"  # Replace with your actual input CSV path
    example_output_path = "data/fact_retail.parquet"

    # Create a dummy CSV file for demonstration if it doesn't exist
    # In a real scenario, you would upload your data or specify its location.
    Path("data").mkdir(exist_ok=True)
    if not Path(example_input_path).exists():
        print(f"Creating dummy CSV: {example_input_path}")
        with open(example_input_path, 'w') as f:
            f.write("InvoiceNo,StockCode,Description,Quantity,InvoiceDate,UnitPrice,CustomerID,Country\n")
            f.write("536365,85123A,WHITE HANGING HEART T-LIGHT HOLDER,6,12/1/2010 8:26,2.55,17850,United Kingdom\n")
            f.write("536366,22752,SET 7 BABUSHKA NESTING BOXES,2,12/1/2010 8:28,7.65,17850,United Kingdom\n")
            f.write("536367,21755,LOVE BIRD HOUSE,3,12/1/2010 8:34,3.39,13047,United Kingdom\n")

    etl(example_input_path, example_output_path)